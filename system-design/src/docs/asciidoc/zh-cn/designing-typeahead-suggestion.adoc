== 设计 Typeahead Suggestion

让我们设计一个实时建议服务，它会在用户输入文本进行搜索时向他们推荐术语。
类似服务：自动推荐、Typeahead 搜索难度：中

[[what_is_typehead_suggestion]]
=== 1. 什么是Typeahead Suggestion?

Typeahead suggestions enable users to search for known and frequently searched terms.
As the user types into the search box, it tries to predict the query based on the characters the user has entered and gives a list of suggestions to complete the query.
Typeahead suggestions help the user to articulate their search queries better.
It’s not about speeding up the search process but rather about guiding the users and lending them a helping hand in constructing their search query.

Typeahead建议使用户能够搜索已知的和经常搜索的术语。
当用户在搜索框中输入内容时，它会尝试根据用户输入的字符预测用户的查询信息，并提供完整的查询建议列表。
提前键入建议可帮助用户更好地完成其搜索查询。
这不是为了加快搜索过程，而是为了指导用户并帮助他们构建搜索查询。


[[requirements_and_goals_of_the_system]]
=== 2.	需求和系统目标

*功能性需求:* 当用户输入查询条件时，我们的服务应该提供10条与用户输入的查询相关的术语。

*非功能性需求:* 推荐的查询术语应该是即时的出现，用户应该能够在200ms内看到系统提供的建议的内容。

[[basic_system_design_and_algorithm]]
=== 3. 基本系统设计和算法

我们将要解决的问题是，要存储大量的字符串，以至于用户可以使用任意前缀进行搜索。我们的服务将会根据给到的前缀进行匹配，建议下一条搜索用的术语。
例如，如果我们的数据包含以下术语：‘cap‘，’cat‘，’captain‘，或 ’captial‘，当用户输入‘cap’时，我们的系统应该建议使用‘cap‘，’captain‘，和 ’captial‘。

由于我们必须以最小的延迟处理大量查询，因此我们需要提出一种可以有效存储数据的方案，以便可以快速查询数据。
因此我们不能依赖某些数据库；我们需要将索引以高效的数据结构存储在内存中。

可以满足我们目的的最合适的数据结构之一是Trie（发音为“try”）。
trie 是一种树状数据结构，用于存储短语，其中每个节点以顺序方式存储短语的字符。
例如，如果我们需要以trie型数据结构存储数据：“cap，cat，caption，captain，capital”，它看起来如下所示：

image::D:/OneDrive/桌面/system design/Typeahead/tire_structure.png[]

现在如果用户已经输入 'cap'，我们的服务会遍历trie型数据结构到节点'p'，找到以'cap'为前缀的所有术语。（例如，'cap-tion'，'cap-ital'等）

我们可以合并只有一个分支的节点来节约存储空间。此时存储数据的trie型数据结构如下：

image::D:/OneDrive/桌面/system design/Typeahead/trie_merge_node.png[]

*我们应该在tire型数据结构中区分大小写吗？* 为了搜索简单，在此假定我们不区分大小写。

*如何查找顶层建议？* 现在我们可以找到所有给定前缀的术语，我们如何知道应该建议的前 10 个术语是什么？
一个简单的解决方案是在每个尾节点保存搜索次数，例如，如果用户搜索了 “CAPTAIN” 100 次，搜索了 “CAPTION” 500次，我们可以将此数字与短语的最后一个字符保存在一起。
因此，现在如果用户输入了“CAP”，我们知道前缀“CAP”下搜索最多的单词是“CAPTION”。
因此，给定一个前缀，我们可以遍历其下的子树以找到最适合的建议。

*给定一个前缀，遍历其子树需要多少时间？* 考虑到我们需要索引的数据量，我们应该期望一棵巨大的树。
即使遍历子树也需要很长时间，例如，短语“system design interview questions”的深度是30。
由于我们有非常严格的延迟要求，因此我们需要提高查询效率。

*我们可以存储每个节点的热门推荐吗？* 这肯定可以加快我们的搜索速度，但需要大量额外的存储空间。
我们可以在每个节点上存储前 10 个推荐，可以将其返回给用户。我们必须承受存储容量的大幅增加才能达到所需的效率。

我们可以通过存储终端节点的引用而不是存储整个短语来优化存储。要找到推荐项，我们需要使用终端节点中的父引用进行后置遍历。
我们还需要存储每个引用的频率，以跟踪热门推荐。

*将如何构建这个trie型数据结构？* 我们可以有效地自下而上地构建我们的trie。每个父节点将以递归方式调用所有子节点，以计算其热门推荐和计数。
父节点将组合来自其所有子节点的热门推荐，以确定最终的热门推荐。

*如何更新trie型数据结构？* 假设每天有50亿次搜索，这将会有每秒大约60K的查询。
如果我们尝试为每个查询更新我们的trie，它将是非常消耗资源，这也可能会阻塞我们的读取请求。
处理此问题的一种解决方案是在一定间隔后离线更新我们的 trie 型数据结构。

当新查询进来时，我们可以记录它们并跟踪它们的查询频率。
我们可以记录每个查询，也可以进行采样并记录每第 1000 个查询。
例如，如果我们不想显示搜索次数少于 1000 次的术语，则每记录第 1000 个搜索的术语是安全的。

我们可以设置一个 https://en.wikipedia.org/wiki/MapReduce[Map-Reduce (MR)]来定期处理所有日志中记录的数据，比如每小时一次。
这些 MR 作业将计算过去一小时内所有搜索词的频率。然后，我们可以用这些新数据更新 tire 数据结构。
我们可以拍摄 trie 的当前快照，并使用所有新术语及其频率对其进行更新。
我们应该离线执行此操作，因为我们不希望更新 trie 树结构的操作阻塞读取查询。
我们可以有两种选择：

. 我们可以在每台服务器上复制一份 trie 数据以离线更新它。更新完成后，我们可以使用新的数据并丢弃旧数据。
. 另一种选择是我们可以为每个trie服务器配置主从服务。我们可以使用master为流量提供服务的同时，更新slave上的数据。
更新完成后，我们可以使slave服务器成为我们的新的master服务器。我们稍后可以更新旧master，然后它又开始为流量提供服务。


如何更新typeahead推荐的频率？因为我们保存了每个节点推荐的频率，因此我们也需要更新它们。
我们只需更新频率的差异，而不是从头开始重新计算所有搜索词的搜索次数。
如果我们保留过去 10 天内搜索的所有字词的计数，则需要从不再包含的时间段中减去计数，并将包含的新时间段的计数相加。
我们可以根据每个项的 https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average[指数移动平均值（EMA）]来加减频率。
在EMA中，我们更加重视最新数据。它也被称为指数加权移动平均值。



在trie数据结构中插入一个新术语后，我们将转到短语的终端节点并增加其频率。
由于我们在每个节点中存储前 10 个查询，因此此特定搜索词可能会跳入其他几个节点的前 10 个查询。
因此，我们需要更新这些节点的前 10 个查询。
我们必须从节点遍历到根节点。对于每个父查询，我们检查当前查询是否属于前 10 名的一部分。如果是这样，我们会更新相应的频率。
如果不是，我们会检查当前查询的频率是否足够大，可以成为前 10 名的一部分。如果是这样，我们将插入此新术语并删除频率最低的术语。


*我们如何从trie中删除一个术语？* 假设由于一些法律或仇恨或盗版等问题，我们必须从trie结构中删除一个术语。当定期更新发生时，
我们可以从 trie 结构中完全删除这些术语，同时，我们可以在每个服务器中添加一个过滤层，该过滤层将在此类术语发送给用户之前将其删除。

*推荐的排名标准可能有所不同？*  除了简单的计数之外，对于术语排名，我们还必须考虑其他因素，例如新鲜度、用户位置、语言、人口统计、个人历史等。


[[permanent_storage_of_the_trie]]
=== 4.	Trie的持久化


*如何将 trie 结构存储在文件中，当机器重新启动以便我们可以轻松重建我们的 trie 结构？*
我们可以定期拍摄trie结构的快照并将其存储在文件中。这将使我们能够在服务器出现故障时重建 trie。
为了存储数据，我们可以从根节点开始，逐级保存trie。对于每个节点，我们可以存储它包含的字符以及它有多少个子节点。
在每个节点之后，我们应该放置它的所有子节点。
让假设trie结构如下所示：

image::xxx[]

如果我们用上面的方案存储trie结构，我们将获得如下形式的内容：“C2,A2,R1,T,P,O1,D”，使用这中形式的数据，可以很方便的重建trie结构。

如果您已经注意到，我们不会存储每个节点的热门推荐及其计数。
因为很难存储这些信息;由于我们的 trie 是自上而下存储的，因此我们不会在父节点之前创建子节点，
因此，没有简单的方法来存储它们的引用。为此，我们必须重新计算所有带有计数的顶级项。
这可以在我们构建 trie 结构时完成。每个节点将计算其热门推荐并将其传递给其父节点。
每个父节点将合并其所有子节点的结果，以找出其主要推荐。


If you’ve noticed, we are not storing top suggestions and their counts with each node.
It is hard to store this information; as our trie is being stored top down, we don’t have child nodes created before the parent,
so there is no easy way to store their references.For this, we have to recalculate all the top terms with counts.
This can be done while we are building the trie.
Each node will calculate its top suggestions and pass it to its parent.
Each parent node will merge results from all of its children to figure out its top suggestions.

[[sacle_estimation]]
=== 5. 规模估算

如果我们构建一个和谷歌相同规格的服务，那么每天预期有50亿次搜索，这将带来每秒大约60k次查询。


由于在 50 亿次查询中会有很多重复项，假设其中只有 20% 是唯一的。如果我们只想索引前 50% 的搜索词，我们可以过滤掉许多搜索频率较低的查询。
假设我们要为 1 亿个唯一术语构建索引。


*存储评估：* 如果平均每个查询由 3 个单词组成，并且一个单词的平均长度为 5 个字符，这将为我们提供 15 个字符的平均查询大小。
假设我们需要 2 个字节来存储一个字符，我们将需要 30 个字节来存储一个平均查询。
因此，我们将需要总存储：

[source,text]
----
100 million * 30 bytes => 3 GB
----

可以预期这些数据每天都会有所增长，但我们也应该删除一些不再搜索的术语。
假设每天有 2% 的新查询，并且如果我们在过去一年中保持索引，那么我们应该期望的总存储量为：

[source,text]
----
3GB + (0.02 * 3 GB * 365 days) => 25 GB
----

[[data_partition]]
=== 6. 数据分片

虽然我们的索引可以很容易地放在一台服务器上，但我们仍然可以对它进行分区，以满足我们对更高效率和更低延迟的要求。
我们如何有效地对数据进行分区以将其分发到多个服务器上？

a. *基于范围的分区：* 加入我们根据短语的第一个字母将短语存储在单独的分区中怎么办？
因此，我们将所有以字母“A”开头的短语保存在一个分区中，并将以字母“B”开头的短语保存到另一个分区中，依此类推。
我们甚至可以将某些不太频繁出现的短语保存到同一一个数据库分区中。
使用这种静态分区方案，以便我们始终可以存储并以可预测的方式搜索术语。
+
这种方法的主要问题是它可能导致服务器不平衡，例如，如果我们决定将所有以字母“E”开头的短语放入一个数据库分区，但后来我们意识到以字母“E”开头的短语太多，无法保存到一个数据库分区。
+
可以看到，上述问题将发生在每个静态定义的方案中。
无法计算每个分区是否适合成为一台静态服务器。

b. *基于服务器最大容量的分区：* 假设我们根据服务器的最大内存容量尝试进行分区。
只要有可用的内存，就可以继续将数据存储在此服务器上。
每当子树无法放入服务器时，我们就会在此分割分区以将该范围的字符分配给该服务器，并在下一台服务器上存储后续的字符串子树，以重复此过程。
假设第一个尝试的服务器是可以存储从“A”到“AABC”的所有短语，这意味着在下一个服务器将从“AABD”开始存储。
如果第二台服务器最多可以存储到“BXA”，那么下一台服务器将从“BXB”开始存储，依此类推。
在这种分区方案中，可以保留一个哈希表来快速查询：+
服务器 1，A-AABC +
服务器 2，AABD-BXA +
服务器 3， BXB-CDA +
对于查询，如果用户键入了“A”，必须同时查询服务器 1 和 2 以找到最佳建议。
当用户键入“AA”时，仍然需要查询服务器 1 和 2，但是当用户键入“AAA”时，只需要查询服务器 1。
+
可以在尝试服务器前面加一个负载均衡器，它可以存储此映射关系和重定向流量。
此外，如果我们从多个服务器进行查询，要么需要在服务器端合并结果以计算最终的最佳结果，要么让在客户端合并结果计算最佳结果。
如果更喜欢在服务器端执行此操作，我们需要在负载均衡器和尝试服务器之间引入另一层服务器（称之为聚合器）。
这些服务器将聚合来自多个尝试服务器的结果，并将排名靠前的结果返回给客户端。
+
基于最大容量的分区仍会带来热点问题，例如，如果对以“cap”开头的术语有很多查询，则与其他服务器相比，将具有高负载。

c. *基于术语哈希值的分区：* 每个术语都将使用哈希函数生成一个服务器编号，然后将术语存储在该服务器上。
这将使术语随机分布，从而最大限度地减少热点问题。
要找到一个术语的预建议结果，必须查询所有服务器，然后汇总结果。

[[cache]]
=== 7. 缓存

我们应该意识到，缓存搜索最多的词对。服务非常有帮助。
将有一小部分查询产生大部分的流量。
我们可以在尝试服务器前面部署单独的缓存服务器，其中包含最常搜索的术语及其预置建议。
应用程序服务器应该在访问尝试服务器之前，在这些缓存服务器上查询是否具有所需的搜索词。

还可以构建一个简单的机器学习（ML）模型，该模型可以尝试根据简单的计数、个性化或趋势数据等来预测每个建议的搜索次数，并缓存这些术语。


[[replication_and_load_balancer]]
=== 8. 备份和负载均衡器

应该为尝试服务器提供副本，以实现负载平衡和容错。
还需要一个负载均衡器来跟踪我们的数据分区方案并根据前缀重定向流量。

[[fault_tolerance]]
=== 9. 容错

当尝试服务器出现故障时会发生什么？
如上所述，可以有一个主从配置；如果主设备死亡，则从设备可以在故障转移后接管主设备。
任何恢复的服务器都可以根据上次快照重建尝试服务器。

[[typeahead_client]]
=== 10. Typeahead Client

我们可以在客户端进行以下优化，以提升用户体验：

1. 如果用户在50毫秒内未做任何操作，客户端应仅尝试访问服务器。
2. 如果用户不断打字，客户端应取消正在进行的请求。
3. 最初，客户端可以等待户输入几个字符之后开始向服务器发起请求。
4. 客户端可以从服务器预取一些数据以保存未来的请求。
5. 客户端可以在本地存储最近建议的历史记录。最近的历史记录有很高的概率被重新使用。
6. 尽早与服务器建立连接是最重要的因素之一。一旦用户打开搜索引擎网站，客户端就可以打开与服务器的连接。
因此，当用户输入第一个字符时，客户端不会浪费时间来建立连接。
7. 服务器可以将其缓存的某些部分数据推送到 CDN 和互联网服务提供商 (ISP) 以提高效率。

[[personalization]]
=== 11. 个性化

用户将根据其历史搜索、位置、语言等收到一些预置建议。
可以将每个用户的个人历史记录分别存储在服务器上，也可以将它们缓存在客户端上。
服务器可以在将这些个性化术语添加到最终集合中，然后发送给用户。
个性化搜索应始终排在其他因素之前。
